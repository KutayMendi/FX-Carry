{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59492b8-5920-49c3-92e5-1f19f1fe95e8",
   "metadata": {},
   "source": [
    "# FX Carry Trade Project\n",
    "Fx carry is a tried and tested staple of FX strategies. It involves borrowing in a low interest rate currency and investing in a high interest rate currency. You profit from what is called the \"interest rate differential\". So all we need to do is find a pair of currencies with historically different rates. This project will simulate this strategy over time. I obtain/approximate short-term interest rates for the the two currencies and the historical FX rates. Then, I calculate the daily/monthly returns which is simply the interest earned from the diffrential plus any gain/loss from currency movements. I then compare this strategy to a simple buy-and-hold of the currencies to illustrate its risk/return profile.\n",
    "\n",
    "This project itself is rather simple, but I mainly chose this project to \"quantify\" my experience at LSE trading society's Emerging Markets subcommittee. Although the currencies here are not from emerging economies, most of my strategies in the subcommittee involved FX trades, which is what I build on here.\n",
    "\n",
    "I downloaded fx csv data from FRED (5Y time frame, daily data)\n",
    "I downloaded rates csv data from BIS (5Y time frame, monthly data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe5f8a-a9cd-426d-a4bc-e80356c6552f",
   "metadata": {},
   "source": [
    "#### First I start off the basic imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d02f4e-6226-432b-a5cc-e754ed56a2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21bf6ca-7c19-437c-9a6b-60abab03fa4f",
   "metadata": {},
   "source": [
    "#### Parameters and Paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891aa683-9227-4a31-9733-0beb3ec28879",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 3             # long top-n by carry\n",
    "bottom_n = 3             #short bottom-n by carry\n",
    "trans_cost = 1.0           #transaction cost per unit turnover (measured in bps)\n",
    "\n",
    "target_vol = 0.10         # annualized target portfolio vol\n",
    "vol_window = 20            # rolling window (days) for realized vol\n",
    "lev_min = 0.2           # leverage floor\n",
    "lev_max = 2.0           # leverage cap\n",
    "\n",
    "fx_path = \"data/fx.csv\"    #wide daily levels for various currencies\n",
    "rates_path = \"data/rates.csv\"  #monthly policy rates for various currencies\n",
    "out_dir = \"output\"\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5e1e8-6857-498c-a451-7d9f602e7394",
   "metadata": {},
   "source": [
    "#### Build DataFrames from the FRED and BIS CSVs:\n",
    "##### Firstly for FRED:\n",
    "Because some of the FX data is swapped, we want to swap them to have them all in form USD per XXX. It simply makes it easier to code with one \"master currence\" that the others are quoted in terms of.\n",
    "The folder layout on GitHub for reference is:\n",
    "- ..data/\n",
    "- ....fred/\n",
    "- ......DEXUSEU.csv\n",
    "- ......DEXUSUK.csv\n",
    "- ......etc\n",
    "- ....bis/\n",
    "- ......bis_EUR.scv\n",
    "- ......bis_GBP.csv\n",
    "- ......etc\n",
    "\n",
    "Our outputs will be\n",
    "- `fx` which is daily FX levels (with columns `EURUSD`, `GBPUSD`, etc)\n",
    "- `rates_m` which is monthly polciy rates (columns are `EUR, GBP, ...`)\n",
    "- `rates_fx` which is daily policy rates aligned to `fx`'s index and columns (which just makes the dataset clearer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd1016f-67fb-4765-943c-3919c3b3ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fred_dir = \"data/fred\"\n",
    "bis_dir = \"data/bis\"\n",
    "\n",
    "#FRED FX mapping: final column name maps to a tuple (filename, invert_needed) where invert_needed=True means we need to inver from XXXYYY to YYYXXX\n",
    "fred_map = {\n",
    "    \"EURUSD\": (\"DEXUSEU.csv\", False),  # USD per EUR\n",
    "    \"GBPUSD\": (\"DEXUSUK.csv\", False),  # USD per GBP\n",
    "    \"AUDUSD\": (\"DEXUSAL.csv\", False),  # USD per AUD\n",
    "    \"NZDUSD\": (\"DEXUSNZ.csv\", False),  # USD per NZD\n",
    "    \"JPYUSD\": (\"DEXJPUS.csv\", True),   # JPY per USD \n",
    "    \"CHFUSD\": (\"DEXSZUS.csv\", True),   # CHF per USD \n",
    "    \"CADUSD\": (\"DEXCAUS.csv\", True),   # CAD per USD \n",
    "    \"NOKUSD\": (\"DEXNOUS.csv\", True),   # NOK per USD \n",
    "    \"SEKUSD\": (\"DEXSDUS.csv\", True),   # SEK per USD\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb353f4-a631-46c9-9ddb-4569df2617a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fred(path, out_col, invert):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[FRED] missing {os.path.basename(path)} -> skip {out_col}\")\n",
    "        return None\n",
    "    df = pd.read_csv(path, na_values=[\".\"], parse_dates=[\"DATE\"])\n",
    "    # FRED csv format is usually: DATE + one data column\n",
    "    series_col = [c for c in df.columns if c != \"DATE\"][0]\n",
    "    df = df.rename(columns={\"DATE\": \"date\", series_col: out_col})\n",
    "    df[out_col] = pd.to_numeric(df[out_col], errors=\"coerce\")\n",
    "    df = df.sort_values(\"date\").set_index(\"date\")  \n",
    "    #for columns that need to be invered, we just reciprocate them\n",
    "    if invert:\n",
    "        df[out_col] = 1.0 / df[out_col].replace(0, np.nan)  \n",
    "    return df[[out_col]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79dd840b-cfd3-4cd0-8fc8-dab3e39f49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will now build the dataframe for fred.\n",
    "def build_fx_df():\n",
    "    frames = []  #we start the list that will contain each single series dataframe, ie one per currency pair\n",
    "    for col, (fname, inv) in fred_map.items():\n",
    "        f = read_fred(os.path.join(fred_dir, fname), col, inv)  #builds the full file path (folder + file name) and calls our `read_fred()`\n",
    "        if f is not None:\n",
    "            frames.append(f)\n",
    "    if not frames:\n",
    "        raise FileNotFoundError(\"No FRED series found under data/fred/.\")\n",
    "    #Next we stitch all these 1-column data frames side by side into a single table, aligning them by dates        \n",
    "    fx_local = pd.concat(frames, axis=1).sort_index().ffill()   #ffill() forward fills missing values, as FRED has gaps (it uses previous value for blanks)\n",
    "    fx_local.index.name = \"date\"\n",
    "    # keep columns in our order defined in `fred_map`\n",
    "    fx_local = fx_local[[c for c in fred_map if c in fx_local.columns]] \n",
    "    return fx_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce34ec50-f035-4eaf-8b27-770515aec02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FRED] missing DEXUSEU.csv -> skip EURUSD\n",
      "[FRED] missing DEXUSUK.csv -> skip GBPUSD\n",
      "[FRED] missing DEXUSAL.csv -> skip AUDUSD\n",
      "[FRED] missing DEXUSNZ.csv -> skip NZDUSD\n",
      "[FRED] missing DEXJPUS.csv -> skip JPYUSD\n",
      "[FRED] missing DEXSZUS.csv -> skip CHFUSD\n",
      "[FRED] missing DEXCAUS.csv -> skip CADUSD\n",
      "[FRED] missing DEXNOUS.csv -> skip NOKUSD\n",
      "[FRED] missing DEXSDUS.csv -> skip SEKUSD\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No FRED series found under data/fred/.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m build_fx_df()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mbuild_fx_df\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m         frames.append(f)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m frames:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo FRED series found under data/fred/.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#Next we stitch all these 1-column data frames side by side into a single table, aligning them by dates        \u001b[39;00m\n\u001b[32m     11\u001b[39m fx_local = pd.concat(frames, axis=\u001b[32m1\u001b[39m).sort_index().ffill()   \u001b[38;5;66;03m#ffill() forward fills missing values, as FRED has gaps (it uses previous value for blanks)\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No FRED series found under data/fred/."
     ]
    }
   ],
   "source": [
    "build_fx_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b77e8-0ca5-427c-8074-a019e1229aa4",
   "metadata": {},
   "source": [
    "##### Now for BIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8aae3c-1ab2-4db1-9215-3e1187023525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BIS per-country policy rates (percent or decimal depending on export)\n",
    "DATE_CANDS  = [\"TIME_PERIOD\",\"TIME\",\"DATE\",\"Obs Period\",\"Period\",\"REF_DATE\"]\n",
    "VALUE_CANDS = [\"OBS_VALUE\",\"Value\",\"Obs Value\",\"OBS_VALUE (Percent per annum)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8803c8a-e0cc-46a6-9b70-1ba5aa4efb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_col(df, cands):\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for c in cands:\n",
    "        if c.lower() in low:\n",
    "            return low[c.lower()]\n",
    "    raise ValueError(f\"Missing one of {cands}; got {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7bec6-6f38-41a3-9b54-a7b4bd848c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bis_file(path, code):\n",
    "    df = pd.read_csv(path)\n",
    "    dcol = pick_col(df, DATE_CANDS)\n",
    "    vcol = pick_col(df, VALUE_CANDS)\n",
    "    df = df[[dcol, vcol]].copy()\n",
    "    df[dcol] = pd.to_datetime(df[dcol], errors=\"coerce\")\n",
    "    df[vcol] = pd.to_numeric(df[vcol], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[dcol, vcol]).sort_values(dcol)\n",
    "    df = df.drop_duplicates(subset=[dcol], keep=\"last\")\n",
    "    df = df.set_index(dcol).rename(columns={vcol: code})\n",
    "    return df[[code]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5656454-bced-4360-a60a-9d39362ded89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rates_m_df():\n",
    "    files = [f for f in os.listdir(bis_dir) if re.match(r\"bis_[A-Za-z]{3}\\.csv$\", f)]\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\"No BIS files like bis_EUR.csv found in data/bis/\")\n",
    "    frames = []\n",
    "    for fname in files:\n",
    "        code = fname.split(\"_\")[1].split(\".\")[0].upper()  # bis_EUR.csv -> EUR\n",
    "        try:\n",
    "            s = read_bis_file(os.path.join(bis_dir, fname), code)\n",
    "            frames.append(s)\n",
    "        except Exception as e:\n",
    "            print(f\"[BIS] skip {fname}: {e}\")\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"No valid BIS series parsed.\")\n",
    "    rates_local = pd.concat(frames, axis=1).sort_index()\n",
    "    # if given in percent (e.g. 5.25), convert to decimals\n",
    "    med = rates_local.median(numeric_only=True).median()\n",
    "    if pd.notna(med) and med > 1.0:\n",
    "        rates_local = rates_local / 100.0\n",
    "    rates_local.index.name = \"date\"\n",
    "    # standard order (only those present)\n",
    "    wanted = [\"EUR\",\"GBP\",\"AUD\",\"NZD\",\"JPY\",\"CHF\",\"CAD\",\"NOK\",\"SEK\"]\n",
    "    rates_local = rates_local[[c for c in wanted if c in rates_local.columns]]\n",
    "    return rates_local\n",
    "\n",
    "# --- run + align\n",
    "fx = build_fx_df()          # daily FX levels, columns like EURUSD, GBPUSD, ...\n",
    "rates_m = build_rates_m_df()# monthly policy rates, columns like EUR, GBP, ...\n",
    "\n",
    "# forward-fill monthly to daily calendar, then align to FX columns by 3-letter prefix\n",
    "rates_d = rates_m.reindex(fx.index, method=\"ffill\")\n",
    "pair2ccy = {c: c[:3] for c in fx.columns}\n",
    "rate_cols = [pair2ccy[c] for c in fx.columns if pair2ccy[c] in rates_d.columns]\n",
    "rates_fx = rates_d[rate_cols].copy()\n",
    "rates_fx.columns = fx.columns  # align names to pairs for convenience\n",
    "\n",
    "print(\"fx:\", fx.shape, \"| rates_m:\", rates_m.shape, \"| rates_fx (daily-aligned):\", rates_fx.shape)\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
